# ğŸš€ IQuest-Coder-V1-14B å¿«é€Ÿéƒ¨ç½²æŒ‡å—

## ğŸ“‹ ä¸ºä»€ä¹ˆé€‰æ‹© 14B æ¨¡å‹ï¼Ÿ

âœ… **æ˜¾å­˜å……è¶³** - åªéœ€ 8-10GBï¼Œä½ çš„ 32GB æ˜¾å­˜ç»°ç»°æœ‰ä½™  
âœ… **é€Ÿåº¦å¿«** - æ¨ç†é€Ÿåº¦ 40-60 tokens/sï¼ˆæ˜¯ 40B çš„ 2 å€ï¼‰  
âœ… **è´¨é‡ä¼˜ç§€** - ä»£ç ç”Ÿæˆè´¨é‡æ¥è¿‘ 40B  
âœ… **æ”¯æŒé•¿ä¸Šä¸‹æ–‡** - å¯å¤„ç† 32K tokens  
âœ… **é«˜å¹¶å‘** - å¯åŒæ—¶å¤„ç†å¤šä¸ªè¯·æ±‚  
âœ… **ç¨³å®šå¯é ** - ä¸ä¼š OOM  

## ğŸ¯ ä¸€é”®éƒ¨ç½²ï¼ˆ3 åˆ†é’Ÿï¼‰

### æ­¥éª¤ 1: ä¸Šä¼ æ–‡ä»¶åˆ°æœåŠ¡å™¨

```bash
# åœ¨æœ¬åœ°ç”µè„‘æ‰§è¡Œ
scp -r iquest-coder-deploy ubuntu@ä½ çš„æœåŠ¡å™¨IP:~/
```

### æ­¥éª¤ 2: SSH è¿æ¥æœåŠ¡å™¨

```bash
ssh ubuntu@ä½ çš„æœåŠ¡å™¨IP
```

### æ­¥éª¤ 3: è¿›å…¥ç›®å½•å¹¶å¯åŠ¨

```bash
cd iquest-coder-deploy

# ä½¿ç”¨ Docker Compose å¯åŠ¨ï¼ˆæ¨èï¼‰
docker-compose -f docker-compose-14b.yml up -d

# æŸ¥çœ‹å¯åŠ¨æ—¥å¿—ï¼ˆç­‰å¾…æ¨¡å‹ä¸‹è½½ï¼‰
docker-compose -f docker-compose-14b.yml logs -f
```

**é¦–æ¬¡å¯åŠ¨è¯´æ˜**ï¼š
- æ¨¡å‹å¤§å°çº¦ 8GB
- ä¸‹è½½æ—¶é—´çº¦ 5-10 åˆ†é’Ÿï¼ˆå–å†³äºç½‘é€Ÿï¼‰
- ä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿï¼ˆhf-mirror.comï¼‰
- çœ‹åˆ° "Application startup complete" è¡¨ç¤ºå¯åŠ¨æˆåŠŸ

### æ­¥éª¤ 4: æµ‹è¯• API

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# è·å–æ¨¡å‹ä¿¡æ¯
curl http://localhost:8000/v1/models

# æµ‹è¯•ä»£ç ç”Ÿæˆ
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "IQuestLab/IQuest-Coder-V1-14B-Instruct",
    "messages": [
      {"role": "user", "content": "å†™ä¸€ä¸ª Python å‡½æ•°å®ç°å¿«é€Ÿæ’åº"}
    ],
    "temperature": 0.6,
    "top_p": 0.85,
    "max_tokens": 2048
  }'

# æˆ–è¿è¡Œå®Œæ•´æµ‹è¯•è„šæœ¬
python3 test_api_14b.py
```

## ğŸ“Š ç›‘æ§å’Œç®¡ç†

### æŸ¥çœ‹æœåŠ¡çŠ¶æ€
```bash
docker-compose -f docker-compose-14b.yml ps
```

### æŸ¥çœ‹æ—¥å¿—
```bash
# å®æ—¶æ—¥å¿—
docker-compose -f docker-compose-14b.yml logs -f

# æœ€è¿‘ 100 è¡Œ
docker-compose -f docker-compose-14b.yml logs --tail=100
```

### æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µ
```bash
# å®æ—¶ç›‘æ§
watch -n 1 nvidia-smi

# æˆ–å•æ¬¡æŸ¥çœ‹
nvidia-smi
```

### é‡å¯æœåŠ¡
```bash
docker-compose -f docker-compose-14b.yml restart
```

### åœæ­¢æœåŠ¡
```bash
docker-compose -f docker-compose-14b.yml down
```

### æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨
```bash
docker stats iquest-coder-14b
```

## ğŸ§ª æ€§èƒ½æµ‹è¯•

### 1. åŸºç¡€åŠŸèƒ½æµ‹è¯•
```bash
python3 test_api_14b.py
```

### 2. ä»£ç ç”Ÿæˆæµ‹è¯•
```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="dummy"
)

# æµ‹è¯• 1: ç®€å•å‡½æ•°
response = client.chat.completions.create(
    model="IQuestLab/IQuest-Coder-V1-14B-Instruct",
    messages=[
        {"role": "user", "content": "å†™ä¸€ä¸ª Python å‡½æ•°è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—"}
    ],
    temperature=0.6,
    top_p=0.85,
    max_tokens=2048
)
print(response.choices[0].message.content)

# æµ‹è¯• 2: å¤æ‚ç®—æ³•
response = client.chat.completions.create(
    model="IQuestLab/IQuest-Coder-V1-14B-Instruct",
    messages=[
        {"role": "user", "content": """
è¯·ç”¨ Python å®ç°ä¸€ä¸ª LRU ç¼“å­˜ç±»ï¼Œè¦æ±‚ï¼š
1. æ”¯æŒ get å’Œ put æ“ä½œ
2. æ—¶é—´å¤æ‚åº¦ O(1)
3. ä½¿ç”¨åŒå‘é“¾è¡¨å’Œå“ˆå¸Œè¡¨
4. æ·»åŠ è¯¦ç»†æ³¨é‡Š
"""}
    ],
    temperature=0.6,
    top_p=0.85,
    max_tokens=4096
)
print(response.choices[0].message.content)
```

### 3. å‹åŠ›æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
```bash
# å®‰è£… Apache Bench
sudo apt-get install apache2-utils

# åˆ›å»ºæµ‹è¯•è´Ÿè½½
cat > test_payload.json << 'EOF'
{
  "model": "IQuestLab/IQuest-Coder-V1-14B-Instruct",
  "messages": [
    {"role": "user", "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åº"}
  ],
  "temperature": 0.6,
  "max_tokens": 1024
}
EOF

# è¿è¡Œå‹åŠ›æµ‹è¯•ï¼ˆ100 ä¸ªè¯·æ±‚ï¼Œ10 ä¸ªå¹¶å‘ï¼‰
ab -n 100 -c 10 -p test_payload.json -T application/json \
  http://localhost:8000/v1/chat/completions
```

## ğŸ“ˆ é¢„æœŸæ€§èƒ½æŒ‡æ ‡

### æ˜¾å­˜ä½¿ç”¨
- **æ¨¡å‹åŠ è½½**: 8-10GB
- **æ¨ç†æ—¶**: 10-12GBï¼ˆåŒ…å« KV Cacheï¼‰
- **å‰©ä½™æ˜¾å­˜**: 20GB+ï¼ˆéå¸¸å……è£•ï¼‰

### æ¨ç†æ€§èƒ½
- **é€Ÿåº¦**: 40-60 tokens/ç§’
- **é¦– token å»¶è¿Ÿ**: 0.5-1 ç§’
- **æœ€å¤§ä¸Šä¸‹æ–‡**: 32K tokens
- **å¹¶å‘èƒ½åŠ›**: æ”¯æŒ 256 ä¸ªå¹¶å‘åºåˆ—

### ä»£ç è´¨é‡
- **ç®€å•ä»»åŠ¡**: ä¼˜ç§€ï¼ˆæ¥è¿‘ 40Bï¼‰
- **å¤æ‚ç®—æ³•**: ä¼˜ç§€
- **ä»£ç å®¡æŸ¥**: ä¼˜ç§€
- **Bug ä¿®å¤**: ä¼˜ç§€

## ğŸ”§ é…ç½®è°ƒä¼˜

### å¦‚æœéœ€è¦æ›´å¿«çš„é€Ÿåº¦
ç¼–è¾‘ `docker-compose-14b.yml`ï¼š
```yaml
environment:
  - MAX_NUM_BATCHED_TOKENS=16384  # å¢åŠ æ‰¹å¤„ç†
  - MAX_NUM_SEQS=512              # å¢åŠ å¹¶å‘
```

### å¦‚æœéœ€è¦æ›´é•¿çš„ä¸Šä¸‹æ–‡
```yaml
environment:
  - MAX_MODEL_LEN=65536           # æ”¯æŒ 64K ä¸Šä¸‹æ–‡
  - MAX_NUM_SEQS=128              # å‡å°‘å¹¶å‘ä»¥èŠ‚çœæ˜¾å­˜
```

### å¦‚æœéœ€è¦èŠ‚çœæ˜¾å­˜
```yaml
environment:
  - GPU_MEMORY_UTILIZATION=0.75   # é™ä½æ˜¾å­˜ä½¿ç”¨
  - MAX_MODEL_LEN=16384           # å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦
```

## ğŸŒ é…ç½®å¤–ç½‘è®¿é—®

### 1. å¼€æ”¾é˜²ç«å¢™
```bash
sudo ufw allow 8000/tcp
sudo ufw reload
```

### 2. é…ç½®è…¾è®¯äº‘å®‰å…¨ç»„
- ç™»å½•è…¾è®¯äº‘æ§åˆ¶å°
- è¿›å…¥äº‘æœåŠ¡å™¨ -> å®‰å…¨ç»„
- æ·»åŠ å…¥ç«™è§„åˆ™ï¼šTCP 8000 ç«¯å£ï¼Œæ¥æº 0.0.0.0/0

### 3. æµ‹è¯•å¤–ç½‘è®¿é—®
```bash
# ä»æœ¬åœ°ç”µè„‘æµ‹è¯•
curl http://ä½ çš„æœåŠ¡å™¨å…¬ç½‘IP:8000/health
```

### 4. é…ç½® Nginx åå‘ä»£ç†ï¼ˆæ¨èï¼‰
```bash
# å®‰è£… Nginx
sudo apt-get install nginx

# åˆ›å»ºé…ç½®
sudo nano /etc/nginx/sites-available/iquest-coder

# æ·»åŠ é…ç½®
server {
    listen 80;
    server_name ä½ çš„åŸŸåæˆ–IP;

    location / {
        proxy_pass http://localhost:8000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
        
        # è¶…æ—¶è®¾ç½®
        proxy_connect_timeout 300s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;
    }
}

# å¯ç”¨é…ç½®
sudo ln -s /etc/nginx/sites-available/iquest-coder /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl reload nginx
```

## ğŸ› å¸¸è§é—®é¢˜

### 1. æ¨¡å‹ä¸‹è½½æ…¢
**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å·²é…ç½®å›½å†…é•œåƒï¼Œå¦‚æœè¿˜æ˜¯æ…¢ï¼Œå¯ä»¥æ‰‹åŠ¨ä¸‹è½½
# åœ¨æœåŠ¡å™¨ä¸Šæ‰§è¡Œ
export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download IQuestLab/IQuest-Coder-V1-14B-Instruct
```

### 2. ç«¯å£è¢«å ç”¨
```bash
# æŸ¥çœ‹ç«¯å£å ç”¨
sudo lsof -i :8000

# ä¿®æ”¹ç«¯å£ï¼ˆç¼–è¾‘ docker-compose-14b.ymlï¼‰
ports:
  - "8001:8000"  # æ”¹ä¸º 8001
```

### 3. å®¹å™¨å¯åŠ¨å¤±è´¥
```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
docker-compose -f docker-compose-14b.yml logs

# æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨
nvidia-smi

# é‡æ–°æ„å»ºé•œåƒ
docker-compose -f docker-compose-14b.yml build --no-cache
```

### 4. æ¨ç†é€Ÿåº¦æ…¢
```bash
# æ£€æŸ¥ GPU åˆ©ç”¨ç‡
nvidia-smi

# å¦‚æœ GPU åˆ©ç”¨ç‡ä½ï¼Œå¢åŠ æ‰¹å¤„ç†å¤§å°
# ç¼–è¾‘ docker-compose-14b.yml
environment:
  - MAX_NUM_BATCHED_TOKENS=16384
```

## âœ… éƒ¨ç½²æˆåŠŸæ£€æŸ¥æ¸…å•

- [ ] å®¹å™¨æˆåŠŸå¯åŠ¨
- [ ] å¥åº·æ£€æŸ¥é€šè¿‡ï¼ˆ`/health` è¿”å› 200ï¼‰
- [ ] å¯ä»¥è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆ`/v1/models`ï¼‰
- [ ] ä»£ç ç”ŸæˆåŠŸèƒ½æ­£å¸¸
- [ ] GPU æ˜¾å­˜ä½¿ç”¨æ­£å¸¸ï¼ˆ10-12GBï¼‰
- [ ] æ¨ç†é€Ÿåº¦ç¬¦åˆé¢„æœŸï¼ˆ40-60 tokens/sï¼‰
- [ ] å¤–ç½‘å¯ä»¥è®¿é—®ï¼ˆå¦‚æœéœ€è¦ï¼‰

## ğŸ‰ ä¸‹ä¸€æ­¥

1. **æµ‹è¯•ä»£ç è´¨é‡** - è¿è¡Œ `test_api_14b.py`
2. **é›†æˆåˆ°é¡¹ç›®** - å‚è€ƒ `é›†æˆåˆ°ç°æœ‰é¡¹ç›®.md`
3. **é…ç½®ç›‘æ§** - è®¾ç½®æ—¥å¿—å’Œæ€§èƒ½ç›‘æ§
4. **ä¼˜åŒ–å‚æ•°** - æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè°ƒæ•´é…ç½®

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœé‡åˆ°é—®é¢˜ï¼š
1. æŸ¥çœ‹æ—¥å¿—ï¼š`docker-compose -f docker-compose-14b.yml logs`
2. æ£€æŸ¥ GPUï¼š`nvidia-smi`
3. æŸ¥çœ‹èµ„æºï¼š`docker stats iquest-coder-14b`

**å¼€å§‹éƒ¨ç½²å§ï¼** ğŸš€
