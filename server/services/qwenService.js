import dotenv from 'dotenv'

dotenv.config()

/**
 * è°ƒç”¨é€šä¹‰åƒé—®APIï¼ˆä½¿ç”¨HTTPè¯·æ±‚ï¼‰
 * @param {string} prompt - æç¤ºè¯
 * @param {string} model - æ¨¡å‹åç§°
 *   å¯é€‰å€¼ï¼š
 *   - 'qwen-max': æœ€å¼ºæ¨¡å‹ï¼Œæ•ˆæœæœ€å¥½ï¼Œæˆæœ¬æœ€é«˜ï¼ˆ0.12å…ƒ/åƒtokensï¼‰
 *   - 'qwen-plus': æ¨èï¼Œå¹³è¡¡æ•ˆæœå’Œæˆæœ¬ï¼ˆ0.02å…ƒ/åƒtokensï¼‰
 *   - 'qwen-turbo': å¿«é€Ÿæ¨¡å‹ï¼Œæˆæœ¬ä½ï¼ˆ0.008å…ƒ/åƒtokensï¼‰
 *   - 'qwen-flash': æœ€å¿«æ¨¡å‹ï¼Œæˆæœ¬æœ€ä½ï¼ˆ0.008å…ƒ/åƒtokensï¼‰
 * @returns {Promise<string>} APIè¿”å›çš„æ–‡æœ¬å†…å®¹
 */
export async function callQwenAPI(prompt, model = 'qwen-plus') {
  const apiKey = process.env.DASHSCOPE_API_KEY

  if (!apiKey) {
    throw new Error('è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡')
  }

  // è®°å½•ä½¿ç”¨çš„æ¨¡å‹
  console.log(`ğŸ¤– è°ƒç”¨é€šä¹‰åƒé—®APIï¼Œä½¿ç”¨æ¨¡å‹: ${model}`)
  
  try {
    // ä½¿ç”¨HTTPè¯·æ±‚è°ƒç”¨é€šä¹‰åƒé—®API
    const requestBody = {
      model: model,
      input: {
        messages: [
          {
            role: 'user',
            content: prompt,
          },
        ],
      },
      parameters: {
        max_tokens: 2000,
        temperature: 0.3,
      },
    }
    
    console.log(`ğŸ¤– APIè¯·æ±‚ä½“ä¸­çš„æ¨¡å‹å‚æ•°: ${requestBody.model}`)
    
    const response = await fetch('https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify(requestBody),
    })

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}))
      const errorMessage = errorData.message || errorData.error?.message || `HTTP ${response.status}`
      
      if (response.status === 401) {
        throw new Error('APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥ DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡')
      }
      
      throw new Error(`APIè°ƒç”¨å¤±è´¥: ${errorMessage}`)
    }

    const data = await response.json()
    
    // è®°å½•APIå“åº”ä¸­çš„æ¨¡å‹ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if (data.model) {
      console.log(`ğŸ¤– APIå“åº”ä¸­ä½¿ç”¨çš„æ¨¡å‹: ${data.model}`)
    }
    
    // è§£æè¿”å›ç»“æœ
    if (data.output && data.output.choices && data.output.choices.length > 0) {
      const result = data.output.choices[0].message?.content || ''
      console.log(`ğŸ¤– APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: ${result.length} å­—ç¬¦`)
      return result
    }
    
    if (data.output && data.output.text) {
      return data.output.text
    }
    
    // å¦‚æœæ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼Œè¿”å›åŸå§‹æ•°æ®ç”¨äºè°ƒè¯•
    console.warn('APIè¿”å›æ ¼å¼å¼‚å¸¸:', JSON.stringify(data, null, 2))
    throw new Error('APIè¿”å›æ ¼å¼å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥æ—¥å¿—')
  } catch (error) {
    console.error('é€šä¹‰åƒé—®APIè°ƒç”¨é”™è¯¯:', error)
    
    if (error instanceof Error) {
      throw error
    }
    
    throw new Error(`å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥: ${error.message || 'æœªçŸ¥é”™è¯¯'}`)
  }
}

/**
 * å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨OpenAI APIï¼ˆå¦‚æœé€šä¹‰åƒé—®ä¸å¯ç”¨ï¼‰
 */
export async function callOpenAIAPI(prompt) {
  const apiKey = process.env.OPENAI_API_KEY

  if (!apiKey) {
    throw new Error('è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡')
  }

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'user',
            content: prompt,
          },
        ],
        temperature: 0.3,
        max_tokens: 2000,
      }),
    })

    if (!response.ok) {
      const error = await response.json()
      throw new Error(error.error?.message || 'APIè°ƒç”¨å¤±è´¥')
    }

    const data = await response.json()
    return data.choices[0]?.message?.content || ''
  } catch (error) {
    console.error('OpenAI APIè°ƒç”¨é”™è¯¯:', error)
    throw new Error(`å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥: ${error.message || 'æœªçŸ¥é”™è¯¯'}`)
  }
}

