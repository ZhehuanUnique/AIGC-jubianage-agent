version: '3.8'

services:
  indextts:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: indextts-api
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      # 挂载模型文件（从 E 盘复制到服务器后挂载）
      # checkpoints 目录应包含 config.yaml 和模型权重文件
      - ./checkpoints:/app/checkpoints:ro
      # 输出目录（可写）
      - ./outputs:/app/outputs
    environment:
      - PYTHONUNBUFFERED=1
      - CHECKPOINT_PATH=/app/checkpoints
      - CONFIG_PATH=/app/checkpoints/config.yaml
      - OUTPUT_PATH=/app/outputs
      - PORT=8000
      - DEVICE=cuda  # 如果有 GPU，使用 'cuda'，否则使用 'cpu'
      - USE_FP16=True
      - USE_CUDA_KERNEL=True
      - USE_DEEPSPEED=False
      - LOG_LEVEL=INFO
    # GPU 支持（如果有 NVIDIA GPU）
    # 取消下面的注释以启用 GPU
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    networks:
      - indextts-network
    # 资源限制
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G

networks:
  indextts-network:
    driver: bridge

